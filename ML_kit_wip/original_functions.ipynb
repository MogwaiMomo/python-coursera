{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "434997c7-bf3d-4527-b8cb-baa9fc8f9945",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "0d6b4785-0ff1-49f9-a7c2-595779df9a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries & presets\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "sns.set_theme(style=\"darkgrid\")\n",
    "sns.set(rc={'figure.figsize':(10, 6)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed5a4114-793d-4c2f-a0d6-2b752a8d960e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/IPython/core/interactiveshell.py:3444: DtypeWarning: Columns (11,12,31) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "# load datasets\n",
    "train_data = pd.read_csv(\"train.csv\", sep=\",\", encoding='cp1252')\n",
    "test_data = pd.read_csv(\"test.csv\", sep=\",\", encoding='cp1252')\n",
    "latlong_data = pd.read_csv(\"latlons.csv\", sep=\",\", encoding='cp1252')\n",
    "addresses_data = pd.read_csv(\"addresses.csv\", sep=\",\", encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75f59e03-8ece-4691-aa78-fe3f20e38dae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/g6/f3k4_8hx0zj8db9mvxdvf4180000gn/T/ipykernel_50885/3775568315.py:64: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df[col] = df[col].str.replace(\"\\.0\",\"\")\n"
     ]
    }
   ],
   "source": [
    "# clean input data\n",
    "def clean_data(df):\n",
    "    \n",
    "    # set index\n",
    "    df = df.set_index('ticket_id')\n",
    "    \n",
    "    # fix misformatted columns (floats to str)\n",
    "    df['violation_street_number'] = df['violation_street_number'].astype('str')\n",
    "    df['mailing_address_str_number'] = df['mailing_address_str_number'].astype('str')\n",
    "    \n",
    "    # remove columns not available in the test data set\n",
    "    leaked_cols = df.columns.difference(test_data.columns)\n",
    "    \n",
    "    if not leaked_cols.empty:\n",
    "        leaked_cols = leaked_cols.to_list()\n",
    "        leaked_cols.remove('compliance')\n",
    "        df = df.drop(leaked_cols, axis=1)\n",
    "    \n",
    "    # remove 'not responsible' rows\n",
    "    if 'compliance' in df.columns:\n",
    "        df['compliance'] = df['compliance'].astype('str')\n",
    "        df = df[df[\"compliance\"] != \"nan\"]\n",
    "        \n",
    "    \n",
    "    # remove single-level variables (no information)\n",
    "    df = df.drop(['violation_zip_code', 'grafitti_status', 'clean_up_cost', 'state_fee', 'admin_fee',\n",
    "                  'non_us_str_code'], axis=1)\n",
    "    \n",
    "    # clean & consolidate street address data\n",
    "    \n",
    "    # convert address floats to strings\n",
    "    df['violation_street_number'] = df['violation_street_number'].astype('str')\n",
    "    df['mailing_address_str_number'] = df['mailing_address_str_number'].astype('str')\n",
    "    \n",
    "    # create consolidated columns\n",
    "    df['mailing_address'] = df['mailing_address_str_number'] + ' ' + df['mailing_address_str_name']\n",
    "    df['mailing_address'] = df['mailing_address'].str.translate(str.maketrans('', '', string.punctuation))\n",
    "    df['violation_address'] = df['violation_street_number'] + ' ' + df['violation_street_name']  \n",
    "    \n",
    "    # remove old versions\n",
    "    df = df.drop(['mailing_address_str_number', 'mailing_address_str_name', 'violation_street_number', 'violation_street_name'], axis=1)\n",
    "    \n",
    "    # add geolocation data\n",
    "    geo_address_data = pd.merge(addresses_data, latlong_data, how=\"left\", on=\"address\").set_index(\"ticket_id\")\n",
    "    df = pd.merge(df, geo_address_data, left_index=True, right_index=True)\n",
    "    \n",
    "    # function to reassign dtypes\n",
    "    def set_dtypes(vars_list, df, dtype):\n",
    "        for var in vars_list:\n",
    "            df[var] = df[var].astype(dtype)\n",
    "        return(df)\n",
    "\n",
    "    # set datetime variables \n",
    "    date_vars = ['ticket_issued_date','hearing_date']\n",
    "    df = set_dtypes(date_vars, df, 'datetime64')\n",
    "    \n",
    "    # get time interval between hearing and issued dates\n",
    "    df[\"days_until_hearing\"] = (df[\"hearing_date\"] - df[\"ticket_issued_date\"]).dt.days.astype('float64')\n",
    "\n",
    "    # change all strings to lowercase\n",
    "    for col in df: \n",
    "        if (df[col].dtype.name == 'object'):\n",
    "            df[col] = df[col].str.lower()\n",
    "            df[col] = df[col].str.replace(\"\\.0\",\"\")\n",
    "    \n",
    "    # set category variables\n",
    "    cat_vars = ['agency_name', 'disposition']\n",
    "    df = set_dtypes(cat_vars, df, 'category')\n",
    "    \n",
    "    # return cleaned data\n",
    "    return df\n",
    "\n",
    "# test with both train and test data ... \n",
    "\n",
    "train_cleaned = clean_data(train_data)\n",
    "test_cleaned = clean_data(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "423d3625-1487-4354-8a16-3697e87af4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_df (159880, 7)\n",
      "cat_df (159880, 15)\n",
      "test_num (61001, 7)\n",
      "test_cat (61001, 15)\n",
      "(61001, 2)\n",
      "(61001, 9)\n",
      "(61001, 7)\n"
     ]
    }
   ],
   "source": [
    "# transform data (fit_transform on training, transform on validation/test)\n",
    "def transform_data(train_cleaned, test_cleaned): # add test df after\n",
    "    \n",
    "    ### IMPUTE MISSING VALUES\n",
    "\n",
    "    # impute missing values\n",
    "    df_num = train_cleaned.select_dtypes(np.float64)\n",
    "    df_cat = train_cleaned.select_dtypes(['category', 'object', 'datetime64']).drop([\"compliance\"], axis=1)\n",
    "    print(\"num_df\", df_num.shape)\n",
    "\n",
    "    print(\"cat_df\", df_cat.shape)\n",
    "\n",
    "    # train imputer and save fit-transformed data \n",
    "    imp_cat = SimpleImputer(strategy=\"most_frequent\") \n",
    "    cat_imp = imp_cat.fit_transform(df_cat) # array\n",
    "    cat_imp_df = pd.DataFrame(cat_imp, columns=df_cat.columns, index=df_cat.index) # df form\n",
    "        \n",
    "    # num (use median)\n",
    "    imp_num = SimpleImputer(strategy=\"median\") \n",
    "    num_imp = imp_num.fit_transform(df_num) # array\n",
    "    num_imp_df = pd.DataFrame(num_imp, columns=df_num.columns, index=df_num.index) # df form\n",
    "\n",
    "    ### ENCODE CATEGORICAL DATA - SET THOSE TO INCLUDE HERE ...\n",
    "    \n",
    "    # choose features to include and set as category ...\n",
    "    category_features = [\"agency_name\", \"disposition\"]\n",
    "    for feature in category_features: \n",
    "        cat_imp_df[feature] = cat_imp_df[feature].astype(\"category\")  \n",
    "    cat_df = cat_imp_df[category_features] # vars that will be included in the analysis\n",
    "    \n",
    "    #print(cat_df.shape)\n",
    "\n",
    "    # train encoder and save fit-transformed data\n",
    "    encoder = OneHotEncoder(handle_unknown=\"ignore\")\n",
    "    feature_arr = encoder.fit_transform(cat_df)\n",
    "    feature_names = encoder.get_feature_names(category_features)\n",
    "    df_cat_ohe =  pd.DataFrame(feature_arr.toarray(), columns=feature_names)\n",
    "\n",
    "    #print(df_cat_ohe.shape)\n",
    "\n",
    "    ### SCALE NUMERIC VALUES - USE MIN-MAX AS DEFAULT\n",
    "    \n",
    "    # train scaler and save fit-transformed data\n",
    "    scaler = MinMaxScaler()\n",
    "    scaled_arr = scaler.fit_transform(num_imp_df)\n",
    "    num_scaled_df = pd.DataFrame(scaled_arr, columns=df_num.columns, index=df_num.index) # df form\n",
    "    \n",
    "    #print(num_scaled_df.shape)\n",
    "    train_tr = pd.merge(num_scaled_df, df_cat_ohe, left_index=True, right_index=True) #.fillna(0)\n",
    "    # add compliance back in\n",
    "    train_tr = pd.merge(train_tr, train_cleaned[\"compliance\"], left_index=True, right_index=True)\n",
    "    \n",
    "    \n",
    "    # After fitting all transformers: transform test data using trained imputers & transformers ...\n",
    "    \n",
    "    # impute missing values\n",
    "    test_num = test_cleaned.select_dtypes(np.float64)\n",
    "    test_cat = test_cleaned.select_dtypes(['category', 'object', 'datetime64'])\n",
    "    print(\"test_num\", test_num.shape)\n",
    "    print(\"test_cat\", test_cat.shape)\n",
    "\n",
    "    # transform test data \n",
    "    cat_imp_test = imp_cat.transform(test_cat) # array\n",
    "    cat_imp_test = pd.DataFrame(cat_imp_test, columns=test_cat.columns, index=test_cat.index) # df form\n",
    "        \n",
    "    # num (use median)\n",
    "    num_imp_test = imp_num.transform(test_num) # array\n",
    "    num_imp_test = pd.DataFrame(num_imp_test, columns=test_num.columns, index=test_num.index) # df form\n",
    "\n",
    "    ### ENCODE CATEGORICAL DATA - SET THOSE TO INCLUDE HERE ...\n",
    "    \n",
    "    for feature in category_features: \n",
    "        cat_imp_test[feature] = cat_imp_test[feature].astype(\"category\")  \n",
    "    cat_test = cat_imp_test[category_features] # vars that will be included in the analysis\n",
    "    \n",
    "    print(cat_test.shape)\n",
    "\n",
    "    # transform test data\n",
    "    feature_arr = encoder.transform(cat_test)\n",
    "    feature_names = encoder.get_feature_names(category_features)\n",
    "    test_cat_ohe =  pd.DataFrame(feature_arr.toarray(), columns=feature_names, index=test_num.index)\n",
    "\n",
    "    print(test_cat_ohe.shape)\n",
    "\n",
    "    ### SCALE NUMERIC VALUES - USE MIN-MAX AS DEFAULT\n",
    "    \n",
    "    # transform test data\n",
    "    scaled_arr = scaler.transform(num_imp_test)\n",
    "    num_scaled_test = pd.DataFrame(scaled_arr, columns=test_num.columns, index=test_num.index) # df form\n",
    "    \n",
    "    print(num_scaled_test.shape)\n",
    "        \n",
    "    test_tr = pd.merge(num_scaled_test, test_cat_ohe, left_index=True, right_index=True) #.fillna(0)\n",
    "    \n",
    "    return train_tr, test_tr\n",
    "\n",
    "\n",
    "train_tr, test_tr = transform_data(train_cleaned, test_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8597d4b9-746c-46c5-b650-77269de598ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate X, y from training data\n",
    "\n",
    "def separate_X_from_y(train_tr, target_var):\n",
    "    \n",
    "    y = train_tr[target_var]\n",
    "    X = train_tr.drop(target_var, axis=1)\n",
    "    \n",
    "    return X,y\n",
    "\n",
    "X, y = separate_X_from_y(train_tr, target_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6b1ee857-115f-4357-b28b-20ba22421355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cbd35ac-5125-4e15-b7b8-8af3d16d2279",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Fit 3 models with defaults\n",
    "\n",
    "#### Model 1: logistic regression\n",
    "\n",
    "#### Model 2: random forest\n",
    "Random forest feature importance shows that the top 5 most critical features include lat, lon, and days_until_hearing, late_fee, discount_amount. Categorical feature (\"disposition\" and \"agency_name\") have no importance, so they should be omitted. See below.  \n",
    "\n",
    "#### Model 3: gradient boosted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6ab1d86d-ca2d-4b9e-afd2-35c53ff92b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# isolate most important features\n",
    "most_important_features = [\"lat\", \"lon\", \"days_until_hearing\", \"late_fee\", \"discount_amount\"]\n",
    "\n",
    "X_train = X_train[most_important_features]\n",
    "X_test = X_test[most_important_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "77bc10c3-293b-4ce6-92a0-5af7e8769198",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "grid_values = {'C': [0.1, 1, 10]}\n",
    "\n",
    "# metric to optimize over grid parameters: AUC\n",
    "model_1 = GridSearchCV(LogisticRegression(), param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# print('Cross-validation (AUC)', cross_val_score(model_1, X_train, y_train, cv=5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "e9b07865-f260-4e65-bb1b-db63ce6e6ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# random forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "grid_values = {'min_samples_split': [2, 4, 10], # default is 2\n",
    "               'max_features':[2, 3, 4]} # default is none\n",
    "\n",
    "model_2 = GridSearchCV(RandomForestClassifier(), param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# print('Cross-validation (AUC)', cross_val_score(model_2, X_train, y_train, cv=5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "02bf457c-d1a6-4c69-9668-2dfb9d03b164",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = RandomForestClassifier(max_features=3, min_samples_split=10).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cadaa438-b987-4262-9058-d926683fc047",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient boosted classifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "grid_values = {'learning_rate': [0.005, 0.05, 0.1],\n",
    "               'n_estimators':[100, 500, 100]}\n",
    "\n",
    "model_3 = GridSearchCV(GradientBoostingClassifier(), param_grid = grid_values, scoring = 'roc_auc').fit(X_train, y_train)\n",
    "\n",
    "# print('Cross-validation (AUC)', cross_val_score(model_3, X_train, y_train, cv=5, scoring = 'roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "7351d0bd-e65c-4e5b-835d-94423c67101f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# score the model against validation data\n",
    "def score_model(model, X_test, y_test):\n",
    "    # print prediction results\n",
    "    predictions = model.predict(X_test)\n",
    "    print(classification_report(y_test, predictions))\n",
    "\n",
    "    # calculate AUC score (need over 0.7)\n",
    "    \n",
    "    roc = roc_auc_score(y_test, model.predict_proba(X_test)[:,1])\n",
    "    print(\"Test AUC_score: \", roc)\n",
    "    if 'model.best_params_' in locals():\n",
    "\n",
    "        print('Grid best parameter (max. AUC): ', model.best_params_)\n",
    "        print('Grid best score (AUC): ', model.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b1f00a24-5230-4b38-959d-bcea4ebc65c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat 0.30052794310635933\n",
      "lon 0.29869786595899633\n",
      "days_until_hearing 0.16990681552176354\n",
      "late_fee 0.1324604003878745\n",
      "discount_amount 0.09840697502500634\n"
     ]
    }
   ],
   "source": [
    "# check feature importance\n",
    "def check_feature_importance(X_train, rdf_model):\n",
    "    for name, score in zip(X_train.columns, rdf_model.feature_importances_):\n",
    "        print(name, score)\n",
    "#check_feature_importance(X_train, model_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "95c086a5-74a6-4128-af46-3d183ae5c8f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96     19813\n",
      "           1       0.93      0.11      0.20      1676\n",
      "\n",
      "    accuracy                           0.93     21489\n",
      "   macro avg       0.93      0.55      0.58     21489\n",
      "weighted avg       0.93      0.93      0.90     21489\n",
      "\n",
      "Test AUC_score:  0.7545247045556143\n",
      "Grid best parameter (max. AUC):  {'C': 10}\n",
      "Grid best score (AUC):  0.7646057017190658\n"
     ]
    }
   ],
   "source": [
    "score_model(model_1, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7cebbe0a-9ad7-4631-88f7-4ed353e3e1e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     19813\n",
      "           1       0.72      0.27      0.40      1676\n",
      "\n",
      "    accuracy                           0.94     21489\n",
      "   macro avg       0.83      0.63      0.68     21489\n",
      "weighted avg       0.92      0.94      0.92     21489\n",
      "\n",
      "Test AUC_score:  0.8127172686335614\n",
      "Grid best parameter (max. AUC):  {'max_features': 3, 'min_samples_split': 10}\n",
      "Grid best score (AUC):  0.8074591435616666\n"
     ]
    }
   ],
   "source": [
    "score_model(model_2, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7281db8a-7178-4b92-b733-701e460c6b3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.97     19813\n",
      "           1       0.72      0.28      0.40      1676\n",
      "\n",
      "    accuracy                           0.94     21489\n",
      "   macro avg       0.83      0.63      0.68     21489\n",
      "weighted avg       0.92      0.94      0.92     21489\n",
      "\n",
      "Test AUC_score:  0.8105738234834605\n"
     ]
    }
   ],
   "source": [
    "score_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4184226e-9396-4062-9d5c-d41a23fb64f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97     19813\n",
      "           1       0.82      0.19      0.30      1676\n",
      "\n",
      "    accuracy                           0.93     21489\n",
      "   macro avg       0.88      0.59      0.63     21489\n",
      "weighted avg       0.93      0.93      0.91     21489\n",
      "\n",
      "Test AUC_score:  0.7953095030419868\n",
      "Grid best parameter (max. AUC):  {'learning_rate': 0.1, 'n_estimators': 500}\n",
      "Grid best score (AUC):  0.8017505902569967\n"
     ]
    }
   ],
   "source": [
    "score_model(model_3, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35a7f02a-76c9-4065-ad4b-e54f31ff9051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate the final answer with the test data ...\n",
    "# create FINAL test set for post-model selection answer\n",
    "final_X = test_tr[most_important_features]\n",
    "\n",
    "best_model = model_2 # so far"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "4415c539-a676-436c-83c3-fc92a07b636c",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_X[\"compliance\"] = [i[1] for i in best_model.predict_proba(final_X)]\n",
    "answer = final_X[\"compliance\"].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d426bcb8-cc4e-4cba-9841-b7da2c7991ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ticket_id\n",
       "284932    0.015095\n",
       "285362    0.110369\n",
       "285361    0.005179\n",
       "285338    0.198878\n",
       "285346    0.052675\n",
       "            ...   \n",
       "376496    0.046596\n",
       "376497    0.046596\n",
       "376499    0.018380\n",
       "376500    0.018380\n",
       "369851    0.327579\n",
       "Name: compliance, Length: 61001, dtype: float32"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e6dcf-a019-4021-a244-ec7d63439bf2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
