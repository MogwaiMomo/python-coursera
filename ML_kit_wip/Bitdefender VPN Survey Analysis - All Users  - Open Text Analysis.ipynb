{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "45090bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# generic packages\n",
    "import sys\n",
    "import re, numpy as np, pandas as pd\n",
    "from pprint import pprint\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'\n",
    "\n",
    "# graphing, vis stuff\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models\n",
    "\n",
    "# gensim for topic modelling\n",
    "import gensim, spacy, logging, warnings\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import lemmatize, simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.ldamodel import LdaModel\n",
    "from gensim.models.coherencemodel import CoherenceModel\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98acb187",
   "metadata": {},
   "source": [
    "### Step 1: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "82ae591b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "raw_csv = pd.read_csv(\"bitdefender_vpn_customer_responses.csv\")\n",
    "cols_to_keep = ['Device',\n",
    "                'Browser',\n",
    "                'OS',\n",
    "                'How did you first hear about Bitdefender Premium VPN ?',\n",
    "                'What specifically made you decide you needed Bitdefender Premium VPN in your life? What triggered this decision for you? ',\n",
    "                'What ONE pain or problem has Bitdefender Premium VPN eliminated or lessened for you the most?',\n",
    "                'What ONE benefit have you valued most from using Bitdefender Premium VPN so far?',\n",
    "                'Which, if any, alternatives did you consider before deciding on Bitdefender Premium VPN?',\n",
    "                'Why did you ultimately choose Bitdefender Premium VPN over other options?',\n",
    "                'What 3 adjectives would you use to describe Bitdefender Premium VPN?',\n",
    "                'On a scale of 0 to 10, how happy are you with Bitdefender Premium VPN? ',\n",
    "                'What is the main reason for your rating? (Please be as specific as possible) ',\n",
    "                'Do you currently use any OTHER Bitdefender products or plans (e.g. security/antivirus, identity protection, etc.)?',\n",
    "                'If need be, would it be OK to follow up by email to hear more or help with issues you\\'re having?']\n",
    "\n",
    "all_users = raw_csv[cols_to_keep]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c855af67",
   "metadata": {},
   "source": [
    "### Step 2: Set Up Initial Topic Model (LDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "id": "908033a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all open text questions to analyse ..\n",
    "labels = {'What specifically made you decide you needed Bitdefender Premium VPN in your life? What triggered this decision for you? ':'purchase_prompt',\n",
    "          'What ONE pain or problem has Bitdefender Premium VPN eliminated or lessened for you the most?':'top_pain',\n",
    "          'What ONE benefit have you valued most from using Bitdefender Premium VPN so far?':'top_benefit',\n",
    "          'Why did you ultimately choose Bitdefender Premium VPN over other options?':'comp_edge',\n",
    "          'What is the main reason for your rating? (Please be as specific as possible) ':'rating_reason'}\n",
    "\n",
    "\n",
    "open_text_qs = all_users.rename(columns = labels)\n",
    "happy_open_text_qs = open_text_qs[open_text_qs.iloc[:,10] >=9]\n",
    "unhappy_open_text_qs = open_text_qs[open_text_qs.iloc[:,10] <=5]\n",
    "\n",
    "\n",
    "# create separate dfs per open-text question ...\n",
    "purchase_prompt = pd.DataFrame(open_text_qs.iloc[:,4])\n",
    "top_pain = pd.DataFrame(open_text_qs.iloc[:,5])\n",
    "top_benefit = pd.DataFrame(open_text_qs.iloc[:,6])\n",
    "comp_edge = pd.DataFrame(open_text_qs.iloc[:,8])\n",
    "\n",
    "happy_rating_reason = pd.DataFrame(happy_open_text_qs.iloc[:,11])\n",
    "unhappy_rating_reason = pd.DataFrame(unhappy_open_text_qs.iloc[:,11])\n",
    "\n",
    "df = unhappy_rating_reason\n",
    "df_name = df.columns[0]\n",
    "output_filename = 'unhappy' + df_name + '_lda_analysis.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "e7c71484",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns = [\"content\"]\n",
    "df = df.dropna(subset=['content']).reset_index()\n",
    "data = df.content.values.tolist()\n",
    "\n",
    "def sent_to_words(sentences):\n",
    "    for sent in sentences:\n",
    "        sent = re.sub('\\S*@\\S*\\s?', '', sent)  # remove emails\n",
    "        sent = re.sub('\\s+', ' ', sent)  # remove newline chars\n",
    "        sent = re.sub(\"\\'\", \"\", sent)  # remove single quotes\n",
    "        sent = gensim.utils.simple_preprocess(str(sent), deacc=True) \n",
    "        yield(sent)\n",
    "        \n",
    "data_words = list(sent_to_words(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "56c36d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the bigram and trigram models\n",
    "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
    "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
    "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
    "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
    "\n",
    "# NLTK Stop words\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['from', 'subject', 're', 'edu', 'use', 'not', 'would', 'say', 'could', '_', 'be', 'know', 'good', 'go', 'get', 'do', 'done', 'try', 'many', 'some', 'nice', 'thank', 'think', 'see', 'rather', 'easy', 'easily', 'lot', 'lack', 'make', 'want', 'seem', 'run', 'need', 'even', 'right', 'line', 'even', 'also', 'may', 'take', 'come'])\n",
    "\n",
    "\n",
    "def process_words(texts, stop_words=stop_words, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
    "    \"\"\"Remove Stopwords, Form Bigrams, Trigrams, and Lemmatize\"\"\"\n",
    "    texts = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
    "    texts = [bigram_mod[doc] for doc in texts]\n",
    "    texts = [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
    "    texts_out = []\n",
    "    nlp = spacy.load('en_core_web_sm', disable=['parser', 'ner'])\n",
    "    for sent in texts:\n",
    "        doc = nlp(\" \".join(sent)) \n",
    "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
    "    # remove stopwords once more after lemmatization\n",
    "    texts_out = [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts_out]    \n",
    "    return texts_out\n",
    "\n",
    "data_ready = process_words(data_words)  # processed Text Data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "f7ae73b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_ready)\n",
    "\n",
    "# Create Corpus: Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in data_ready]\n",
    "\n",
    "# create shorthand of running LDA model\n",
    "def generate_models(n_topic):\n",
    "    lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=n_topic, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=10,\n",
    "                                           passes=10,\n",
    "                                           alpha='symmetric',\n",
    "                                           iterations=500,\n",
    "                                           per_word_topics=True)\n",
    "    return lda_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92eae999",
   "metadata": {},
   "source": [
    "### Step 3: Find Model With Best Coherence & Perplexity Score \n",
    "\n",
    "Lower the perplexity better the model.\n",
    "Higher the topic coherence, the topic is more human interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "8c0cf9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_range = list(np.arange(3,31,2)) # [3, 5, 7, 9, 11, 13, 15, 17, 19, 21, 23, 25, 27, 29]\n",
    "all_models = [generate_models(n_topic) for n_topic in topic_range]\n",
    "model_df = pd.DataFrame({'n_topics': topic_range, \n",
    "                         'LDA_model': all_models})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "8508e0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_coherence(lda_model):\n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, corpus=corpus, texts=data_ready, dictionary=id2word, coherence='c_v')\n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "def score_perplexity(lda_model):\n",
    "    return lda_model.log_perplexity(corpus) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "f8d9372c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_df['coherence_score'] = model_df['LDA_model'].apply(lambda x: score_coherence(x))\n",
    "model_df['perplexity_score'] = model_df['LDA_model'].apply(lambda x: score_perplexity(x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64fc1551",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zv/2nwgh22d7js8r34jp1y61tk00000gn/T/ipykernel_63781/2957197067.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'coherence_score'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlda_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'LDA_model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_df' is not defined"
     ]
    }
   ],
   "source": [
    "best_model = model_df.iloc[model_df['coherence_score'].idxmax()]\n",
    "lda_model = best_model['LDA_model']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5401fb22",
   "metadata": {},
   "source": [
    "### Step 4: Isolate The Dominant \"Topic/Theme\" Per Survey Response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8119e3b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'corpus' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zv/2nwgh22d7js8r34jp1y61tk00000gn/T/ipykernel_63781/2411110244.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0mformat_topics_sentences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtexts\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Init output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msent_topics_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Get main topic in each document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'corpus' is not defined"
     ]
    }
   ],
   "source": [
    "def format_topics_sentences(ldamodel=None, corpus=corpus, texts=data):\n",
    "    # Init output\n",
    "    sent_topics_df = pd.DataFrame()\n",
    "\n",
    "    # Get main topic in each document\n",
    "    for i, row_list in enumerate(ldamodel[corpus]):\n",
    "        row = row_list[0] if ldamodel.per_word_topics else row_list            \n",
    "        # print(row)\n",
    "        row = sorted(row, key=lambda x: (x[1]), reverse=True)\n",
    "        # Get the Dominant topic, Perc Contribution and Keywords for each document\n",
    "        for j, (topic_num, prop_topic) in enumerate(row):\n",
    "            if j == 0:  # => dominant topic\n",
    "                wp = ldamodel.show_topic(topic_num)\n",
    "                topic_keywords = \", \".join([word for word, prop in wp])\n",
    "                sent_topics_df = sent_topics_df.append(pd.Series([int(topic_num), round(prop_topic,4), topic_keywords]), ignore_index=True)\n",
    "            else:\n",
    "                break\n",
    "    sent_topics_df.columns = ['Dominant_Topic', 'Perc_Contribution', 'Topic_Keywords']\n",
    "\n",
    "    # Add original text to the end of the output\n",
    "    contents = pd.Series(texts)\n",
    "    sent_topics_df = pd.concat([sent_topics_df, contents], axis=1)\n",
    "    return(sent_topics_df)\n",
    "\n",
    "\n",
    "df_topic_sents_keywords = format_topics_sentences(ldamodel=lda_model, corpus=corpus, texts=data_ready)\n",
    "\n",
    "\n",
    "# Format\n",
    "df_dominant_topic = df_topic_sents_keywords.reset_index()\n",
    "df_dominant_topic.columns = ['Document_No', 'Dominant_Topic', 'Keywords', 'Text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb72480c",
   "metadata": {},
   "source": [
    "### Step 5: Map Back To Original Texts, Keep Only Strong, Single-Topic Responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "a42e4062",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "lda_clustered_df = df_dominant_topic.merge(df, left_index=True, right_index=True).drop(['index'], axis=1)\n",
    "lda_clustered_df = lda_clustered_df.sort_values([\"Dominant_Topic\",'Topic_Perc_Contrib'],ascending=False)\n",
    "\n",
    "# remove entries that have Perc_Contribution of < 0.5\n",
    "lda_clustered_df = lda_clustered_df[lda_clustered_df['Topic_Perc_Contrib'] >= 0.5]\n",
    "lda_clustered_df.to_csv(output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "id": "134612b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% Documents Included:  0.41320754716981134\n"
     ]
    }
   ],
   "source": [
    "# calculate sample coverage - how many responses were included in the final theme summary?\n",
    "included_docs = len(set(lda_clustered_df['Document_No']))\n",
    "total_docs = len(unhappy_open_text_qs)\n",
    "coverage = (included_docs / total_docs)\n",
    "print(\"% Documents Included: \", coverage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a9ff8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
